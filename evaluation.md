This app has been evaluated only in the context of the slate metadata extraction pipeline. Brandeis annotators and Mturk annotators transcribed the content of text boxes on slates. The app was used in two pipelines. The first consisting of slate detection -> slate text component detection -> OCR, where the OCR tool is run with psm mode 7, "treat the image as a single text line". The second consisted of slate detection -> OCR, wheree the OCR tool is run with psm mode 11, "Sparse text. Find as much text as possible in no particular order." 

Evaluation for the app only makes sense in the context of particular datasets and pipelines. Other contexts where we plan to use this app are chyrons and credits. Any application of this app will likely also involve preprocessing of the image (frame) and post processing of the output string. To create a dataset of text in chyrons we can apply text detection using the EAST model and use heuristics to identify candidate segments, then annotate those shots as having or not having a chyron. Then we can either transcribe the text from scratch or apply tesseract and then correct the tesseract output to construct the chyron evaluation set.  
